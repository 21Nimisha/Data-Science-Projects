{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "y = bo + b1x1 + b2x2 + .... + bn*xn\n",
    "\n",
    "ASSUMPTIONS OF LINEAR REGRESSION -\n",
    "\n",
    "1 - Linearity\n",
    "\n",
    "2- Homoscedasticity\n",
    "\n",
    "3 - Multivariate Normality\n",
    "\n",
    "4- Independence of Errors\n",
    "\n",
    "5- lack of Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variables\n",
    "In my data (50 Startup) State in categorical form. so i will use dummy variable to convert them into numerical data. as in regression only quantitive data work. if state - California , newyork - I create 2 dummy variable 1 for california and 0 for newyork.\n",
    "\n",
    "# Dummy variable Trap -\n",
    "never include all dummy variable in data as it will duplicate the varibale. because D2 = 1- D1 we can not have 3 elements in modle same time -\n",
    "Bo - The constant\n",
    "\n",
    "                                             b4 * D1 -  Dummy varibale One\n",
    "\n",
    "                                             b5 * D2 - Dummy variable Two\n",
    "Always OMIT one Dummy Variable. If in dataset there is 10 dummy variable then keep only 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P - Value\n",
    "Small P - value means reject the Null - Hypothesis H0 The p- value is the probability that, If the null hypothesis were true, sampling variation would produce an estimate that is further away from the hypothesised value than our data estimate.\n",
    "\n",
    "The p- value tells us how likely it is to get a result like this if the Null - Hypothesis is true.\n",
    "\n",
    "Example -\n",
    "Ho - The mean of average weight of peanuts in a packet is 70grams.\n",
    "\n",
    "H1 - The mean of average weight of peanuts in a packet is less than 70 grams.\n",
    "\n",
    "H1 what we trying to prove ?\n",
    "\n",
    "Significant Level : ALPHA = 0.05\n",
    "\n",
    "if P- value is less than alpha value 0.05 REJECT NULL HYPOTHESIS Ho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model\n",
    "1 - Select required variable for building model not all variable .\n",
    "\n",
    "WHY -\n",
    "\n",
    "1 - Garbage In Garbage Out\n",
    "\n",
    "2- Not easy to explain and very complicated model.\n",
    "\n",
    "5 Methods of Building a Model\n",
    "1- All - in\n",
    "\n",
    "2 - Backward Elimination\n",
    "\n",
    "3- Forward Selection\n",
    "\n",
    "4- Bidirectional Elimination\n",
    "\n",
    "5- Score Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection -\n",
    "real world data is noisy, and may contain features (variables)\n",
    "that do not necessarily have good correlation with with the output (predicted/dependent) variable. \n",
    "The idea behind ‘Feature selection’ is to study this relation, \n",
    "and select only the variables that show a strong correlation.\n",
    "\n",
    "There are many different kinds of Feature Selections methods —\n",
    "Forward Selection,\n",
    "Recursive Feature Elimination,\n",
    "Bidirectional elimination and\n",
    "Backward elimination. The simplest and the widely used one is Backward elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Elimination -\n",
    "1 - Select a significance (SL) level to stay in the model (eg - Sl = 0.05)\n",
    "\n",
    "2- fit the full model with all possible predictors\n",
    "\n",
    "3- Consider the predictor with the highest P- value. if P > Sl, go to step 4, otherwise go to FINISH..\n",
    "\n",
    "4- Remove the predictor. (that have higher p value)\n",
    "\n",
    "5- Fit the model without the variable (variable with higher p value)\n",
    "\n",
    "Rebuild the model as coefficient , constant going be different after removing variable with higher p- value. go back to step 3 once again, again look for the variable wtith highest p- value in new model , if any remove that , fit the model again. Keep doing until all variable that left p - value are less than significant level, Model prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Selection -\n",
    "1 - select a significant level to enter the model ( eg= Sl = 0.05)\n",
    "\n",
    "2 - Fit all the simple regression models y ~ xn select the one with the lowest p - value. (take dependent variable and take every single independent variable we have y ~ xn)then select which one have lowest p value for IV.\n",
    "\n",
    "3- keep this variable and fit all possible models with one extra predictor added to one you already have.\n",
    "\n",
    "4- consider the predictor with the Lowest P value. if p- value < Sl, go to step 3 otherwise finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use feature selection methods — Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3  144372.41       118671.85        383199.62    New York  182901.99\n",
      "4  142107.34        91391.77        366168.42     Florida  166187.94\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('50_Startups.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     50 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has 4 features — ‘R&D Spend’,‘Administration’,‘Marketing Spend’ and ‘State’. Given these, we have to predict the ‘Profit’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241955</td>\n",
       "      <td>0.724248</td>\n",
       "      <td>0.972900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administration</th>\n",
       "      <td>0.241955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032154</td>\n",
       "      <td>0.200717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing Spend</th>\n",
       "      <td>0.724248</td>\n",
       "      <td>-0.032154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profit</th>\n",
       "      <td>0.972900</td>\n",
       "      <td>0.200717</td>\n",
       "      <td>0.747766</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 R&D Spend  Administration  Marketing Spend    Profit\n",
       "R&D Spend         1.000000        0.241955         0.724248  0.972900\n",
       "Administration    0.241955        1.000000        -0.032154  0.200717\n",
       "Marketing Spend   0.724248       -0.032154         1.000000  0.747766\n",
       "Profit            0.972900        0.200717         0.747766  1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ac1f6d4780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we store the dataframe in 2 numpy arrays — X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we One-hot encode ‘State’, as it is a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, -1] = labelencoder.fit_transform(X[:, -1])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [-1])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the categorical variable ‘State’ has been One-Hot encoded, we normalize ‘R&D Spend’,‘Administration’ and ‘Marketing Spend’ with Sklearn’s ‘StandardScaler’ library. But before that, we split the training and testing data. We fit the scaler on training data, and transform the testing data with this scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we perform normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train[:,3:] = scaler.fit_transform(X_train[:,3:])\n",
    "X_test[:,3:] = scaler.transform(X_test[:,3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all our data has been preprocessed, let’s begin with Backward Elimination. Let’s build a simple regression model and check its score. Later we’ll see how we can improve it with Backward Elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9347068473282425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "print(model.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score seems great. Before we begin with Backward elimination, we need to append ‘1’ at the beginning of our data set. Now, why is this important?\n",
    "The equation of our line (or rather, plane) is y=b+m1.x1+m2.x2+m3.x3+m4.x4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we make a linear model with sklearn, the bias term ‘b’ is calculated separately. However, for performing Backward elimination, we are required to use the linear model provided by statsmodels library — which does not consider the bias term. Hence, by adding a dummy feature with value as ‘1’, our equation becomes y=b.x0+m1.x1+m2.x2+m3.x3+m4.x4 where x0 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.append (arr=np.ones([X_train.shape[0],1]).astype(int), values = X_train, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been preprocessed according to statsmodels library, we begin with analysing the ‘P-value’ of each feature once a linear model is built. We keep a track of the required features in a new array — ‘X_opt;\n",
    "\n",
    "NOTE: Initially, we had 4 features. Now, we have 7 features – 3 numerical, 3 binary (after One-Hot encoding) and a dummy feature with value 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.943\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Fri, 15 Nov 2019   Prob (F-statistic):           3.91e-21\n",
      "Time:                        00:41:08   Log-Likelihood:                -421.10\n",
      "No. Observations:                  40   AIC:                             854.2\n",
      "Df Residuals:                      34   BIC:                             864.3\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       8.202e+04   1185.723     69.170      0.000    7.96e+04    8.44e+04\n",
      "x1          2.743e+04   2129.481     12.879      0.000    2.31e+04    3.18e+04\n",
      "x2          2.647e+04   2569.235     10.301      0.000    2.12e+04    3.17e+04\n",
      "x3          2.812e+04   2267.882     12.401      0.000    2.35e+04    3.27e+04\n",
      "x4          3.573e+04   2547.324     14.025      0.000    3.05e+04    4.09e+04\n",
      "x5           851.3016   1720.699      0.495      0.624   -2645.580    4348.183\n",
      "x6          4519.8828   2398.520      1.884      0.068    -354.495    9394.261\n",
      "==============================================================================\n",
      "Omnibus:                       15.823   Durbin-Watson:                   2.468\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.231\n",
      "Skew:                          -1.094   Prob(JB):                     9.03e-06\n",
      "Kurtosis:                       6.025   Cond. No.                     1.82e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.22e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "X_opt = [0,1,2,3,4,5,6]\n",
    "regressor = sm.OLS(Y_train, X_train[:,X_opt]).fit()\n",
    "print(regressor.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS stands for ‘Ordinary Least Squares’, which essentially trains a Linear model. From the summary, we observe that the higest P-value is for feature 5, which is way over our significance level of 0.05. Hence, we remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     165.6\n",
      "Date:                Fri, 15 Nov 2019   Prob (F-statistic):           3.19e-22\n",
      "Time:                        00:42:21   Log-Likelihood:                -421.24\n",
      "No. Observations:                  40   AIC:                             852.5\n",
      "Df Residuals:                      35   BIC:                             860.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       8.203e+04   1172.687     69.947      0.000    7.96e+04    8.44e+04\n",
      "x1          2.743e+04   2106.330     13.024      0.000    2.32e+04    3.17e+04\n",
      "x2          2.661e+04   2525.870     10.533      0.000    2.15e+04    3.17e+04\n",
      "x3          2.799e+04   2226.402     12.571      0.000    2.35e+04    3.25e+04\n",
      "x4          3.627e+04   2277.386     15.924      0.000    3.16e+04    4.09e+04\n",
      "x5          4192.2658   2280.289      1.838      0.074    -436.966    8821.498\n",
      "==============================================================================\n",
      "Omnibus:                       14.873   Durbin-Watson:                   2.511\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.150\n",
      "Skew:                          -1.038   Prob(JB):                     2.56e-05\n",
      "Kurtosis:                       5.895   Cond. No.                     1.63e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.61e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_opt = [0,1,2,3,4,6]\n",
    "regressor_OLS = sm.OLS(Y_train, X_train[:,X_opt]).fit()\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest P-value is for the last feature, which is above our significance level of 0.05. Hence we remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.945\n",
      "Model:                            OLS   Adj. R-squared:                  0.940\n",
      "Method:                 Least Squares   F-statistic:                     206.1\n",
      "Date:                Fri, 15 Nov 2019   Prob (F-statistic):           1.02e-22\n",
      "Time:                        00:42:49   Log-Likelihood:                -423.08\n",
      "No. Observations:                  40   AIC:                             854.2\n",
      "Df Residuals:                      36   BIC:                             860.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       8.211e+04   1209.854     67.870      0.000    7.97e+04    8.46e+04\n",
      "x1          2.715e+04   2169.046     12.517      0.000    2.28e+04    3.15e+04\n",
      "x2          2.763e+04   2543.435     10.865      0.000    2.25e+04    3.28e+04\n",
      "x3          2.733e+04   2268.919     12.045      0.000    2.27e+04    3.19e+04\n",
      "x4          3.932e+04   1608.085     24.452      0.000    3.61e+04    4.26e+04\n",
      "==============================================================================\n",
      "Omnibus:                       12.937   Durbin-Watson:                   2.333\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               15.674\n",
      "Skew:                          -0.991   Prob(JB):                     0.000395\n",
      "Kurtosis:                       5.341   Cond. No.                     1.35e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.95e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_opt = [0,1,2,3,4]\n",
    "regressor_OLS = sm.OLS(Y_train, X_train[:,X_opt]).fit()\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that all features are below our significance level, which means we can no longer eliminate features. The first 3 features x1,x2 and x3 are binary variables for the feature ‘State’ after One-Hot encoding. Hence, we’re essentially left with 2 features — State and R&D Spend. With these features, we’ll now create a Linear Model with Sklearn and test its score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X[:,[0,1,2,3]], y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[:,3:] = scaler.fit_transform(X_train[:,3:])\n",
    "X_test[:,3:] = scaler.transform(X_test[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.9471689304016889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "print('Model score: '+str(model.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
